{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.spatial import ConvexHull\n",
    "from skimage import morphology\n",
    "import csv as c\n",
    "#存成每個類別的點線 一個檔案 一條線 兩個點 依序放下去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEigenN2D(matrix):\n",
    "    cov = np.cov(matrix.T)\n",
    "    val, vec = np.linalg.eig(cov)\n",
    "    srt = val.argsort()[::-1]\n",
    "    val = val[srt]\n",
    "    vec = vec[:,srt]\n",
    "    if (val[1] < 0):\n",
    "        val[1] = 0\n",
    "    val = val/sum(val)\n",
    "    return val, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEigenN(matrix):\n",
    "    cov = np.cov(matrix.T)\n",
    "    val, vec = np.linalg.eig(cov)\n",
    "    srt = val.argsort()[::-1]\n",
    "    val = val[srt]\n",
    "    vec = vec[:,srt]\n",
    "    if (val[2] < 0):\n",
    "        val[2] = 0\n",
    "    val = val/sum(val)\n",
    "    return val, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighIntensityRoadPoints(data, threshold, clf):\n",
    "    XYZ = data[:,0:3]\n",
    "    print(\"building KDTree\")\n",
    "    XYZKD = cKDTree(XYZ, leafsize=30)\n",
    "    features = []\n",
    "    roadIndex = []\n",
    "    \n",
    "\n",
    "    p1 = data.shape[0]/100\n",
    "    p2 = 0\n",
    "    #t1 = time.time()\n",
    "    #t2 = time.time()\n",
    "    print(\"go\")\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        #intensity index\n",
    "        if (data[i][3] >= 190):\n",
    "            neighborIndex = XYZKD.query_ball_point(XYZ[i], 1)\n",
    "            if len(neighborIndex) >= 3:\n",
    "                neighbors = XYZ[neighborIndex]\n",
    "                val, vec = getEigenN(neighbors)\n",
    "                vec = vec.T\n",
    "                EV1, EV2, EV3 = val[0],val[1],val[2]\n",
    "                VT1, VT2, VT3 = vec[0],vec[1],vec[2]\n",
    "        \n",
    "                for j in range(3):\n",
    "                    VT3[j] = abs(VT3[j])\n",
    "                vertical = -(VT3[2]/sum(VT3) - 1)\n",
    "                \n",
    "                feature = [(EV1-EV2)/EV1, (EV2-EV3)/EV1, EV3/EV1, vertical]\n",
    "                features.append(feature)\n",
    "                roadIndex.append(i)\n",
    "        \n",
    "        if (i > p1):\n",
    "            p1 += data.shape[0]/100\n",
    "            p2 += 1\n",
    "            print(str(p2)+\"%\")\n",
    "        \n",
    "        \n",
    "    results = clf.predict(features)\n",
    "    XYZIIndexes = []\n",
    "    for i in range(len(results)):\n",
    "        if (results[i] == 1):\n",
    "            XYZIIndexes.append(roadIndex[i])\n",
    "    return data[XYZIIndexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadMarkings():\n",
    "    points = None\n",
    "    length = None\n",
    "    width = None\n",
    "    area = None\n",
    "    vec = None\n",
    "    val = None\n",
    "    center = None\n",
    "    barycenter = None\n",
    "    widthCenter = None\n",
    "    lengthCenter = None\n",
    "    boundingPoints = None\n",
    "    \n",
    "    def __init__(self, points):\n",
    "        if type(points) != np.ndarray:\n",
    "            self.points = np.array(points)\n",
    "        else:\n",
    "            self.points = points\n",
    "        self.__setProperties()\n",
    "\n",
    "    \n",
    "    def __setProperties(self):\n",
    "        rec, area = self.__minimumBoundingRectangle(self.points)\n",
    "        self.boundingPoints = rec\n",
    "        edges = []\n",
    "        for i in range(1,4):\n",
    "            edges.append(np.linalg.norm(rec[0]-rec[i]))\n",
    "            \n",
    "        edges = np.array(edges)\n",
    "        srt = edges.argsort()\n",
    "        edges = edges[srt]\n",
    "        srt = srt.tolist()\n",
    "        self.widthCenter = (rec[0] + rec[srt.index(0)+1])/2\n",
    "        self.lengthCenter = (rec[0] + rec[srt.index(1)+1])/2\n",
    "        self.center = (rec[0] + rec[srt.index(2)+1])/2\n",
    "        \n",
    "        self.width = edges[0]\n",
    "        self.length = edges[1]\n",
    "        self.area = area\n",
    "        self.val, self.vec = self.getEigenN(self.points)\n",
    "        self.barycenter = np.average(self.points, axis=0)\n",
    "        \n",
    "    def getEigenN(self, matrix):\n",
    "        cov = np.cov(matrix.T)\n",
    "        val, vec = np.linalg.eig(cov)\n",
    "        srt = val.argsort()[::-1]\n",
    "        val = val[srt]\n",
    "        vec = vec[:,srt]\n",
    "\n",
    "        if (val[1] < 0):\n",
    "            val[1] = 0\n",
    "        val = val/sum(val)\n",
    "    \n",
    "    \n",
    "    \n",
    "        return val, vec\n",
    "    \n",
    "    def __minimumBoundingRectangle(self, points):\n",
    "        \n",
    "        from scipy.ndimage.interpolation import rotate\n",
    "        pi2 = np.pi/2.\n",
    "\n",
    "        # get the convex hull for the points\n",
    "        conv = ConvexHull(points)\n",
    "        hull_points = points[conv.vertices]\n",
    "\n",
    "        # calculate edge angles\n",
    "        edges = np.zeros((len(hull_points)-1, 2))\n",
    "        edges = hull_points[1:] - hull_points[:-1]\n",
    "\n",
    "        angles = np.zeros((len(edges)))\n",
    "        angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
    "\n",
    "        angles = np.abs(np.mod(angles, pi2))\n",
    "        angles = np.unique(angles)\n",
    "\n",
    "        # find rotation matrices\n",
    "        # XXX both work\n",
    "        rotations = np.vstack([\n",
    "            np.cos(angles),\n",
    "            np.cos(angles-pi2),\n",
    "            np.cos(angles+pi2),\n",
    "            np.cos(angles)]).T\n",
    "        #     rotations = np.vstack([\n",
    "        #         np.cos(angles),\n",
    "        #         -np.sin(angles),\n",
    "        #         np.sin(angles),\n",
    "        #         np.cos(angles)]).T\n",
    "        rotations = rotations.reshape((-1, 2, 2))\n",
    "\n",
    "        # apply rotations to the hull\n",
    "        rot_points = np.dot(rotations, hull_points.T)\n",
    "\n",
    "        # find the bounding points\n",
    "        min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
    "        max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
    "        min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
    "        max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
    "\n",
    "        # find the box with the best area\n",
    "        areas = (max_x - min_x) * (max_y - min_y)\n",
    "        best_idx = np.argmin(areas)\n",
    "\n",
    "        # return the best box\n",
    "        x1 = max_x[best_idx]\n",
    "        x2 = min_x[best_idx]\n",
    "        y1 = max_y[best_idx]\n",
    "        y2 = min_y[best_idx]\n",
    "        r = rotations[best_idx]\n",
    "\n",
    "        rval = np.zeros((4, 2))\n",
    "        rval[0] = np.dot([x1, y2], r)\n",
    "        rval[1] = np.dot([x2, y2], r)\n",
    "        rval[2] = np.dot([x2, y1], r)\n",
    "        rval[3] = np.dot([x1, y1], r)\n",
    "\n",
    "        return rval, conv.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pixel():\n",
    "    #size of each pixel\n",
    "    size = None\n",
    "    #raw input numpy array (n * m)\n",
    "    rawData = None\n",
    "    #translated numpy array (3 * n), minimal value = 0\n",
    "    __translatedData = None\n",
    "    #min, max and range of x, y and z\n",
    "    shapes = None\n",
    "    #range of x, y and z\n",
    "    ranges = None\n",
    "    #voxelized input data (numpy array xRange * yRange * zRange)\n",
    "    pixels = None\n",
    "    #a list of indexes of rawData\n",
    "    __pointsList = None\n",
    "    #cluster data\n",
    "    clusters = None\n",
    "    \n",
    "    minXY = None\n",
    "    \n",
    "    crossWalk = None\n",
    "    dashLine = None\n",
    "    markings = None\n",
    "    smallDashLine = None\n",
    "    \n",
    "    \n",
    "    __usedClusters = None\n",
    "    \n",
    "    def __init__(self, rawData, size = 0.085, withKDTree = False):\n",
    "        self.rawData = rawData\n",
    "        self.size = size\n",
    "        self.__getNewShapes()\n",
    "        self.pixels = np.zeros(self.ranges[0:2])\n",
    "        self.__pointsList = self.__makeList(self.pixels.size)\n",
    "        self.__loadDataIndexToPointsList()\n",
    "        self.__loadPointsListToPixels(threshold = 0)\n",
    "        self.__cluster()\n",
    "    def __getNewShapes(self):\n",
    "        data = np.copy(self.rawData[:,0:3].T)\n",
    "        maxXYZ = [np.amax(data[i]) for i in range(3)]\n",
    "        minXYZ = [np.amin(data[i]) for i in range(3)]\n",
    "        rangeXYZ = [int(maxXYZ[i]/self.size) - int(minXYZ[i]/self.size) + 1 for i in range(3)]\n",
    "        \n",
    "        self.ranges = rangeXYZ\n",
    "        self.__translatedData = np.array([data[i] - minXYZ[i] for i in range(3)])\n",
    "        self.shapes = {\"xMax\": maxXYZ[0], \"yMax\": maxXYZ[1], \"zMax\": maxXYZ[2],\n",
    "                      \"xMin\": minXYZ[0], \"yMin\": minXYZ[1], \"zMin\": minXYZ[2], \n",
    "                      \"x_range\": rangeXYZ[0], \"y_range\": rangeXYZ[1], \"z_range\": rangeXYZ[2]}\n",
    "        self.minXY = np.array([minXYZ[0], minXYZ[1]])\n",
    "    def __makeList(self, length):\n",
    "        return [None] * length\n",
    "    def __getPointsListIndexFromIJ(self, i, j):\n",
    "        y_r = self.ranges[1]\n",
    "        return i * y_r + j\n",
    "    \n",
    "    def getXYFromIJ(self, ij):\n",
    "        return ij * self.size + self.minXY\n",
    "    \n",
    "    def __loadDataIndexToPointsList(self):\n",
    "        scaledData = self.__translatedData / self.size\n",
    "        \n",
    "        #shape[1]: number of points\n",
    "        for i in range(self.__translatedData.shape[1]):\n",
    "            I, J = [int(scaledData[j][i]) for j in range(2)]\n",
    "            #print([scaledData[j][i] for j in range(3)])\n",
    "            index = self.__getPointsListIndexFromIJ(I, J)\n",
    "            if not self.__pointsList[index]:\n",
    "                self.__pointsList[index] = list()\n",
    "            self.__pointsList[index].append(i)\n",
    "            \n",
    "    def __loadPointsListToPixels(self, threshold = 3):\n",
    "        for vi in range(len(self.__pointsList)):\n",
    "            if self.__pointsList[vi]:\n",
    "                pointsInside = len(self.__pointsList[vi])\n",
    "                if (pointsInside > threshold):\n",
    "                    i, j = self.__getIJFromPointsListIndex(vi)\n",
    "                    self.pixels[i][j] = pointsInside\n",
    "    def __getIJFromPointsListIndex(self, index):\n",
    "        y_r = self.ranges[1]\n",
    "        i, j = divmod(index, y_r)\n",
    "        return i, j\n",
    "    def __cluster(self):\n",
    "        #distance threshold\n",
    "        crossDistanceMax = 30*0.065/self.size\n",
    "        crossDistanceMin = 1*0.065/self.size\n",
    "        dashDistanceMax = 320*0.065/self.size\n",
    "        dashDistanceMin = 70*0.065/self.size\n",
    "        smallDashDistanceMax = 35*0.065/self.size\n",
    "        smallDashDistanceMin = 10*0.065/self.size\n",
    "        \n",
    "        \n",
    "        #numbers\n",
    "        crossWalkThreshold = 2\n",
    "        dashLineThreshold = 3\n",
    "        smallDashLineThreshold = 2\n",
    "        \n",
    "        #direction difference \n",
    "        crossDirectionThreshold = 20\n",
    "        straightDirectionThreshold = 30\n",
    "        smallDashDirectionThreshold = 10\n",
    "        \n",
    "        rows = self.ranges[0]\n",
    "        cols = self.ranges[1]\n",
    "\n",
    "        bag = []\n",
    "        kernel = [(0,-2),(0,-1),(0,1),(0,2),(-1,-1),(-1,0),(-1,1),(1,-1),(1,0),(1,1),(-2,0),(2,0)]\n",
    "        intensityData = np.copy(self.pixels)\n",
    "        \n",
    "        #---connect parts\n",
    "        for i in range(2, rows - 2):\n",
    "            for j in range(2, cols - 2):\n",
    "\n",
    "                if (intensityData[i][j] >= 1):\n",
    "                    cluster = []\n",
    "                    near = [(i, j)]\n",
    "                    while(len(near) != 0):\n",
    "                        point = near.pop()\n",
    "                        cluster.append(point)\n",
    "                        px, py = point\n",
    "                        intensityData[px][py] = 0\n",
    "                        for offset in kernel:\n",
    "                            tmpx = px + offset[0]\n",
    "                            tmpy = py + offset[1]\n",
    "                            if (tmpx >= rows) or (tmpy >= cols):\n",
    "                                continue\n",
    "                            if intensityData[tmpx][tmpy] >= 1:\n",
    "                                intensityData[tmpx][tmpy] = 0\n",
    "                                near.append(tuple((tmpx, tmpy)))\n",
    "\n",
    "                    bag.append(cluster)\n",
    "        #connect parts---\n",
    "        \n",
    "        #---make mark\n",
    "        self.clusters = []\n",
    "        for i in range(len(bag)):\n",
    "            if (len(bag[i]) > 20):\n",
    "                RM = RoadMarkings(bag[i])\n",
    "                self.clusters.append(RM)\n",
    "        #make mark---\n",
    "        \n",
    "        \n",
    "        #connect marks---\n",
    "\n",
    "        dashLine = []\n",
    "        crossWalk = []\n",
    "        \n",
    "        centers = np.array([rm.center for rm in self.clusters])\n",
    "        RMKD = cKDTree(centers ,leafsize = 30)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.__usedClusters = [False] * len(self.clusters)\n",
    "        \n",
    "        #cross walk\n",
    "        discovered = [False] * len(self.clusters)\n",
    "        \n",
    "        for i in range(len(discovered)):\n",
    "            if not discovered[i]:\n",
    "                discovered[i] = True\n",
    "                pending = [i]\n",
    "                group = []\n",
    "                while len(pending) > 0:\n",
    "                    current = pending.pop()\n",
    "                    if 20*0.065/self.size<self.clusters[current].length<90*0.065/self.size:\n",
    "                        if 1.5*0.065/self.size<self.clusters[current].width <10*0.065/self.size:\n",
    "                            #is line\n",
    "                            group.append(current)\n",
    "                            neighborIndex = set(RMKD.query_ball_point(centers[current], crossDistanceMax))\n",
    "                            without = set(RMKD.query_ball_point(centers[current], crossDistanceMin))\n",
    "                            neighborIndex = list(neighborIndex.difference(without))\n",
    "                            \n",
    "                            for j in range(0, len(neighborIndex)):\n",
    "                                cluID = neighborIndex[j]\n",
    "                                if not discovered[cluID]:\n",
    "                                    if 20*0.065/self.size<self.clusters[cluID].length<90*0.065/self.size:\n",
    "                                        if 1.5*0.065/self.size<self.clusters[cluID].width <10*0.065/self.size:\n",
    "                                            diff = (self.clusters[current].center - self.clusters[cluID].center)/   ((np.array(self.clusters[cluID].vec.T[1]) + np.array(self.clusters[current].vec.T[1]))/2)\n",
    "                                            #print(\"hmm\",diff)\n",
    "                                            if abs(diff[0]-diff[1]) <= crossDirectionThreshold:\n",
    "                                                pending.append(cluID)\n",
    "                                                discovered[cluID] = True\n",
    "                                else:\n",
    "                                    continue\n",
    "                if len(group) >= crossWalkThreshold:\n",
    "                    crossWalk.append(group)\n",
    "                    for idx in group:\n",
    "                        self.__usedClusters[idx] = True\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        #dash line\n",
    "        discovered = np.array(self.__usedClusters)\n",
    "        \n",
    "        for i in range(len(discovered)):\n",
    "            if not discovered[i]:\n",
    "                discovered[i] = True\n",
    "                pending = [i]\n",
    "                group = []\n",
    "                while len(pending) > 0:\n",
    "                    current = pending.pop()\n",
    "                    if 20*0.065/self.size<self.clusters[current].length<60*0.065/self.size:\n",
    "                        if 1.5*0.065/self.size<self.clusters[current].width <10*0.065/self.size:\n",
    "                            #is line\n",
    "                            group.append(current)\n",
    "                            neighborIndex = set(RMKD.query_ball_point(centers[current], dashDistanceMax))\n",
    "                            without = set(RMKD.query_ball_point(centers[current], dashDistanceMin))\n",
    "                            neighborIndex = list(neighborIndex.difference(without))\n",
    "                            for j in range(0, len(neighborIndex)):\n",
    "                                cluID = neighborIndex[j]\n",
    "                                if not discovered[cluID]:\n",
    "                                    if 20*0.065/self.size<self.clusters[cluID].length<60*0.065/self.size:\n",
    "                                        if 1.5*0.065/self.size<self.clusters[cluID].width <10*0.065/self.size:\n",
    "                                            diff = (self.clusters[current].center - self.clusters[cluID].center)/   ((np.array(self.clusters[cluID].vec.T[0]) + np.array(self.clusters[current].vec.T[0]))/2)\n",
    "                                            if abs(diff[0]-diff[1]) <= straightDirectionThreshold:\n",
    "                                                pending.append(cluID)\n",
    "                                                discovered[cluID] = True\n",
    "                                else:\n",
    "                                    continue\n",
    "                if len(group) >= dashLineThreshold:\n",
    "                    dashLine.append(group)\n",
    "                    for idx in group:\n",
    "                        self.__usedClusters[idx] = True\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        \n",
    "        #markings\n",
    "        markings = []\n",
    "        discovered = np.array(self.__usedClusters)\n",
    "        for i in range(len(discovered)):\n",
    "            if not discovered[i]:\n",
    "                discovered[i] = True\n",
    "                if 50*0.065/self.size<self.clusters[i].length<130*0.065/self.size:\n",
    "                    if 8*0.065/self.size<self.clusters[i].width <20*0.065/self.size:\n",
    "                        markings.append([i])\n",
    "                        self.__usedClusters[i] = True\n",
    "        \n",
    "        #smallDashLine\n",
    "        smallDashLine = []\n",
    "        discovered = np.array(self.__usedClusters)\n",
    "        for i in range(len(discovered)):\n",
    "            if not discovered[i]:\n",
    "                discovered[i] = True\n",
    "                pending = [i]\n",
    "                group = []\n",
    "                while len(pending) > 0:\n",
    "                    current = pending.pop()\n",
    "                    if 5*0.085/self.size<self.clusters[current].length<14*0.085/self.size:\n",
    "                        if 1.75*0.085/self.size<self.clusters[current].width <3.25*0.085/self.size:\n",
    "                            #is line\n",
    "                            group.append(current)\n",
    "                            neighborIndex = set(RMKD.query_ball_point(centers[current], smallDashDistanceMax))\n",
    "                            without = set(RMKD.query_ball_point(centers[current], smallDashDistanceMin))\n",
    "                            neighborIndex = list(neighborIndex.difference(without))\n",
    "                            for j in range(0, len(neighborIndex)):\n",
    "                                cluID = neighborIndex[j]\n",
    "                                if not discovered[cluID]:\n",
    "                                    if 5*0.085/self.size<self.clusters[cluID].length<14*0.085/self.size:\n",
    "                                        if 1.75*0.085/self.size<self.clusters[cluID].width <3.25*0.085/self.size:\n",
    "                                            diff = (self.clusters[current].center - self.clusters[cluID].center)/   ((np.array(self.clusters[cluID].vec.T[0]) + np.array(self.clusters[current].vec.T[0]))/2)\n",
    "                                            if abs(diff[0]-diff[1]) <= smallDashDirectionThreshold:\n",
    "                                                pending.append(cluID)\n",
    "                                                discovered[cluID] = True\n",
    "                                                print(self.clusters[current].val[0])\n",
    "                                else:\n",
    "                                    continue\n",
    "                if len(group) >= smallDashLineThreshold:\n",
    "                    smallDashLine.append(group)\n",
    "                    for idx in group:\n",
    "                        self.__usedClusters[idx] = True\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.crossWalk = crossWalk\n",
    "        self.dashLine = dashLine\n",
    "        self.markings = markings\n",
    "        self.smallDashLine = smallDashLine\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #---connect marks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_hull(point, hull, tolerance=1e-12):\n",
    "    return all(\n",
    "        (np.dot(eq[:-1], point) + eq[-1] <= tolerance)\n",
    "        for eq in hull.equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_2_rgb(img):\n",
    "    \n",
    "    new_img = np.zeros((img.shape[0],img.shape[1],3))\n",
    "        \n",
    "    for i in range(img.shape[0]):\n",
    "        for k in range(img.shape[1]):\n",
    "            if img[i][k] >= 1:\n",
    "                new_img[i][k] = np.array([255,255,255])\n",
    "    \n",
    "    new_img = new_img.astype('uint8')\n",
    "    \n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building KDTree\n",
      "go\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n"
     ]
    }
   ],
   "source": [
    "XYZI = np.genfromtxt(\"lineTest.csv\", delimiter=\",\", usecols=(0,1,2,3))\n",
    "with open('roadClassifier.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "highIntensityRoadPoints = getHighIntensityRoadPoints(XYZI, 190, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = highIntensityRoadPoints.tolist()\n",
    "import csv as c\n",
    "with open(\"QQ.csv\",\"w\") as f:\n",
    "    writer = c.writer(f)\n",
    "    for i in range(len(a)):\n",
    "        writer.writerow(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "with open(\"withGround06_highIntensityRoadPoints.pickle\", \"wb\") as f:\n",
    "    pickle.dump(highIntensityRoadPoints,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"withGround01_highIntensityRoadPoints.pickle\", \"rb\") as f:\n",
    "    highIntensityRoadPoints = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9378764656274973\n",
      "0.9429879961950328\n",
      "0.9422022877864324\n",
      "0.9135065347984087\n",
      "0.9518544386372926\n",
      "0.9409028714718469\n",
      "0.9222903885480573\n",
      "0.9323777526445494\n",
      "0.9275937604585706\n",
      "0.9345588631107093\n",
      "0.9110794375806636\n"
     ]
    }
   ],
   "source": [
    "b = Pixel(highIntensityRoadPoints)\n",
    "q = b.clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5], [6], [13], [27], [29], [30], [35], [41], [57], [59]]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[45, 50], [46, 51], [60, 62, 65]]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.crossWalk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3, 10, 12, 2], [4, 11, 15, 9]]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dashLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 33, 36, 37], [38, 40, 43, 47, 49, 52, 55, 56, 58]]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.smallDashLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp=[]\n",
    "# for i in range(len(b.smallDashLine)):\n",
    "#     with open(str(i)+\"smallD.csv\",\"w\",newline=\"\") as f:\n",
    "#         wr = c.writer(f)\n",
    "#         for idx in b.smallDashLine[i]:\n",
    "#             a = b.clusters[idx].points.tolist()\n",
    "#             for aa in a:\n",
    "#                 wr.writerow(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp=[]\n",
    "# for i in range(len(b._Pixel__usedClusters)):\n",
    "#     if not (b._Pixel__usedClusters[i]):\n",
    "#         with open(str(i)+\"remain.csv\",\"w\",newline=\"\") as f:\n",
    "#             wr = c.writer(f)\n",
    "#             for pt in b.clusters[i].points:\n",
    "#                 wr.writerow(pt.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([0,2,3,4,8,6,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cloudcompare\n",
    "height = [10]\n",
    "\n",
    "#markings\n",
    "tmp = []\n",
    "for i in b.markings:\n",
    "    for j in i:\n",
    "        pts = b.clusters[j].boundingPoints\n",
    "        pts = b.getXYFromIJ(pts).tolist()\n",
    "        for ii in range(0, 3):\n",
    "            for jj in range(ii+1, 4):\n",
    "                tmp.append(pts[ii]+height)\n",
    "                tmp.append(pts[jj]+height)\n",
    "\n",
    "with open(\"_markings.csv\",\"w\",newline=\"\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])\n",
    "\n",
    "#save crosswalk\n",
    "#待完成 用方向 分群\n",
    "\n",
    "tmp = []\n",
    "for i in b.crossWalk:\n",
    "    xyTmp = [[],[]]\n",
    "    for j in i:\n",
    "        pts = b.clusters[j].boundingPoints\n",
    "        for k in range(4):\n",
    "            xyTmp[0].append(pts[k][0])\n",
    "            xyTmp[1].append(pts[k][1])\n",
    "    xyTmp = np.array(xyTmp)\n",
    "    maxX = xyTmp[0].max()\n",
    "    minX = xyTmp[0].min()\n",
    "    maxY = xyTmp[1].max()\n",
    "    minY = xyTmp[1].min()\n",
    "    pt1 = b.getXYFromIJ(np.array([minX,maxY])).tolist()\n",
    "    pt2 = b.getXYFromIJ(np.array([minX,minY])).tolist()\n",
    "    pt3 = b.getXYFromIJ(np.array([maxX,maxY])).tolist()\n",
    "    pt4 = b.getXYFromIJ(np.array([maxX,minY])).tolist()\n",
    "    pts = [pt1,pt2,pt3,pt4]\n",
    "    for ii in range(0, 3):\n",
    "        for jj in range(ii+1, 4):\n",
    "            tmp.append(pts[ii]+height)\n",
    "            tmp.append(pts[jj]+height)\n",
    "        \n",
    "with open(\"_crosswalk.csv\",\"w\",newline=\"\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])\n",
    "\n",
    "#save dashline\n",
    "tmp = []\n",
    "for i in b.dashLine:\n",
    "    centers = []\n",
    "    for j in i:\n",
    "        centers.append(b.getXYFromIJ(b.clusters[j].center).tolist()+height)\n",
    "    \n",
    "    for ii in range(len(i)-1):\n",
    "        tmp.append(centers[ii])\n",
    "        tmp.append(centers[ii+1])\n",
    "\n",
    "with open(\"_dashline.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])\n",
    "        \n",
    "#save small dashline\n",
    "tmp = []\n",
    "for i in b.smallDashLine:\n",
    "    centers = []\n",
    "    for j in i:\n",
    "        centers.append(b.getXYFromIJ(b.clusters[j].center).tolist()+height)\n",
    "    \n",
    "    for ii in range(len(i)-1):\n",
    "        tmp.append(centers[ii])\n",
    "        tmp.append(centers[ii+1])\n",
    "\n",
    "\n",
    "with open(\"_smalldashline.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp=[]\n",
    "# for i in range(len(b._Pixel__usedClusters)):\n",
    "#     if not (b._Pixel__usedClusters[i]):\n",
    "#         for pt in b.clusters[i].points:\n",
    "#             tmp.append(pt.tolist())\n",
    "# import csv as c\n",
    "# with open(\"remain.csv\",\"w\",newline=\"\") as f:\n",
    "#     wr = c.writer(f)\n",
    "#     for i in range(len(tmp)):\n",
    "#         wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save markings\n",
    "tmp = []\n",
    "for i in b.markings:\n",
    "    for j in i:\n",
    "        tmp += b.clusters[j].points.tolist()\n",
    "import csv as c\n",
    "with open(\"tr3markings.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save crosswalk\n",
    "tmp = []\n",
    "for i in b.crossWalk:\n",
    "    for j in i:\n",
    "        tmp += b.clusters[j].points.tolist()\n",
    "import csv as c\n",
    "with open(\"tr3cross.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dashline\n",
    "tmp = []\n",
    "for i in b.dashLine:\n",
    "    for j in i:\n",
    "        tmp += b.clusters[j].points.tolist()\n",
    "import csv as c\n",
    "with open(\"tr3straight.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save smalldashline\n",
    "tmp = []\n",
    "for i in b.smallDashLine:\n",
    "    for j in i:\n",
    "        tmp += b.clusters[j].points.tolist()\n",
    "import csv as c\n",
    "with open(\"tr3smallDash.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save roadmarkings\n",
    "tmp = []\n",
    "for rm in b.clusters:\n",
    "    for i in range(len(rm.points)):\n",
    "        tmp.append(rm.points[i])\n",
    "import csv as c\n",
    "with open(\"rms.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(b._Pixel__usedClusters)):\n",
    "    if not (b._Pixel__usedClusters[i]):\n",
    "        points = b.clusters[i].points.T\n",
    "        xrange = max(points[0]) - min(points[0]) + 1\n",
    "        yrange = max(points[1]) - min(points[1]) + 1\n",
    "        minX = min(points[0])\n",
    "        minY = min(points[1])\n",
    "        binaryMap = np.zeros((xrange, yrange), dtype=bool)\n",
    "        points = points.T\n",
    "        for x,y in points:\n",
    "            binaryMap[x-minX][y-minY] = True\n",
    "        \n",
    "        \n",
    "        dil = morphology.binary_dilation(binaryMap)\n",
    "        closed = morphology.binary_closing(dil)\n",
    "        out = morphology.medial_axis(closed)\n",
    "        \n",
    "        bag = []\n",
    "        for ii in range(out.shape[0]):\n",
    "            for jj in range(out.shape[1]):\n",
    "                if (out[ii][jj]):\n",
    "                    bag.append([ii+minX, jj+minY])\n",
    "        bag = np.array(bag)\n",
    "        if len(bag) > 20:\n",
    "            try:\n",
    "                b.clusters[i] = RoadMarkings(bag)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "#         tmp = np.zeros((out.shape[0],out.shape[1],3))\n",
    "#         for ii in range(out.shape[0]) :\n",
    "#             for j in range(out.shape[1]):\n",
    "#                 if (out[ii][j]):\n",
    "#                     tmp[ii][j] = np.array([255,255,255])\n",
    "#                 else:\n",
    "#                     tmp[ii][j] = np.array([0,0,0])\n",
    "#         tmp = tmp.astype(\"uint8\")\n",
    "#         Image.fromarray(tmp).save(str(i) + \"QQ.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "tmp=[]\n",
    "breakPointDistance = 20\n",
    "longMarkThreshold = 50\n",
    "kernel = [[-1,-1],[-1,0],[-1,1],[0,-1],[0,1],[1,-1],[1,0],[1,1]]\n",
    "\n",
    "\n",
    "for i in range(len(b._Pixel__usedClusters)):\n",
    "    if not (b._Pixel__usedClusters[i]):\n",
    "        points = b.clusters[i].points\n",
    "        transP = points.T\n",
    "        minX = min(transP[0])\n",
    "        minY = min(transP[1])\n",
    "        xrange = max(transP[0]) - min(transP[0]) + 1\n",
    "        yrange = max(transP[1]) - min(transP[1]) + 1\n",
    "        binaryMap = np.zeros((xrange, yrange), dtype=int)\n",
    "        for row in range(binaryMap.shape[0]):\n",
    "            for col in range(binaryMap.shape[1]):\n",
    "                binaryMap[row][col] = -1\n",
    "\n",
    "        for j in range(len(points)):\n",
    "            x, y = points[j]\n",
    "            binaryMap[x-minX][y-minY] = j\n",
    "        \n",
    "        \n",
    "        \n",
    "        ptKD = cKDTree(points)\n",
    "        ptDir = []\n",
    "        \n",
    "        #每點的值\n",
    "        for idx in range(len(points)):\n",
    "            neighborIndex = ptKD.query(points[idx], 30)[1]\n",
    "            mini = min(len(points), len(neighborIndex))\n",
    "            neighborIndex = neighborIndex[:mini]\n",
    "            \n",
    "            if len(neighborIndex) >= 3:\n",
    "                neighbors = points[neighborIndex]\n",
    "                val, vec = getEigenN2D(neighbors)\n",
    "                vec = vec.T\n",
    "                ptDir.append([val[0], vec[0]])\n",
    "            else:\n",
    "                #something impossible\n",
    "                print(123132)\n",
    "                ptDir.append([0, [0,0]])\n",
    "        \n",
    "        #一段一段\n",
    "        limbs = []\n",
    "        discovered = [False] * len(points)\n",
    "        \n",
    "        for j in range(len(points)):\n",
    "            if not (discovered[j]):\n",
    "                pending = [j]\n",
    "                part = []\n",
    "                breakPoint = []\n",
    "                while (len(pending) >= 1):\n",
    "                    current = pending.pop()\n",
    "                    discovered[current] = True\n",
    "                    if ptDir[current][0] > 0.9:\n",
    "                        part.append(current)\n",
    "                        x, y = points[current]\n",
    "                        x -= minX\n",
    "                        y -= minY\n",
    "                        for xd, yd in kernel:\n",
    "                            tx = x+xd\n",
    "                            ty = y+yd\n",
    "                            if tx >= xrange or tx < 0:\n",
    "                                continue\n",
    "                            if ty >= yrange or ty < 0:\n",
    "                                continue\n",
    "                            \n",
    "                            nei = binaryMap[tx][ty]\n",
    "                            if nei != -1:\n",
    "                                if not discovered[nei]:\n",
    "                                    pending.append(nei)\n",
    "                                    discovered[nei] = True\n",
    "                    else:\n",
    "                        breakPoint.append(current)\n",
    "                        if j == current:\n",
    "                            \n",
    "                            discovered[current] = False\n",
    "                        #斷點\n",
    "                \n",
    "                if len(part) >= 25:\n",
    "                    limbs.append([part, breakPoint])\n",
    "        \n",
    "        \n",
    "        #X, Y, limb index, point's index\n",
    "        BPs = []\n",
    "        for limbIdx in range(len(limbs)):\n",
    "            limb = limbs[limbIdx]\n",
    "            for j in range(len(limb[1])):\n",
    "                ptIdx = limb[1][j]\n",
    "                pt = points[ptIdx].tolist() + [limbIdx, ptIdx]\n",
    "                BPs.append(np.array(pt))\n",
    "                \n",
    "        #merge table\n",
    "        table = [set([j]) for j in range(len(limbs))]\n",
    "        typeTable = [\"\"] * len(limbs)\n",
    "        for j in range(len(BPs)-1):\n",
    "            for k in range(j+1, len(BPs)):\n",
    "                dis = np.linalg.norm(BPs[j][:2] - BPs[k][:2])\n",
    "\n",
    "                #near enough\n",
    "                if dis < breakPointDistance:\n",
    "                    pt1 = BPs[j][3]\n",
    "                    pt2 = BPs[k][3]\n",
    "                    \n",
    "                    limbIndex1 = BPs[j][2]\n",
    "                    limbIndex2 = BPs[k][2]\n",
    "                    #same direction\n",
    "                    if np.linalg.norm(  ptDir[pt1][1] - ptDir[pt2][1]) < 0.2:\n",
    "                        print(np.linalg.norm(  ptDir[pt1][1] - ptDir[pt2][1]))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        #for merge\n",
    "                        table[limbIndex1].add(limbIndex2)\n",
    "\n",
    "                    else:\n",
    "                        #for type\n",
    "\n",
    "                        ptsNum1 = len(limbs[limbIndex1][0])\n",
    "                        ptsNum2 = len(limbs[limbIndex2][0])\n",
    "                        \n",
    "\n",
    "                        if (max(ptsNum1,ptsNum2)>longMarkThreshold) and (min(ptsNum1,ptsNum2)<longMarkThreshold):\n",
    "                            if ptsNum1 > ptsNum2:\n",
    "                                typeTable[limbIndex1] = \"road\"\n",
    "                                typeTable[limbIndex2] = \"stop\"\n",
    "                            else:\n",
    "                                typeTable[limbIndex1] = \"stop\"\n",
    "                                typeTable[limbIndex2] = \"road\"\n",
    "        \n",
    "        \n",
    "\n",
    "                                \n",
    "#         #is this even correct????\n",
    "        for j in range(0, len(table)):\n",
    "            for k in range(0, len(table)):\n",
    "                if j==k:\n",
    "                    continue\n",
    "                if len(table[j].intersection(table[k])) > 0:\n",
    "                    table[j] = table[j].union(table[k])\n",
    "                    table[k] = set()\n",
    "        \n",
    "#         print(table)\n",
    "#         print(typeTable)\n",
    "        #merge\n",
    "\n",
    "        \n",
    "        merged = []\n",
    "        for limbSet in table:\n",
    "            if len(limbSet) > 0:\n",
    "                pts = []\n",
    "                limbType = \"NN\"\n",
    "                for limbIdx in limbSet:\n",
    "                    for p in limbs[limbIdx][0]:\n",
    "                        pts.append(points[p].tolist())\n",
    "                    if typeTable[limbIdx] == \"road\":\n",
    "                        limbType = \"road\"\n",
    "                    if typeTable[limbIdx] == \"stop\":\n",
    "                        limbType = \"stop\"\n",
    "                #ignore small parts\n",
    "                if len(pts) < 50 and limbType == \"NN\":\n",
    "                    continue\n",
    "                merged.append([pts, limbType])\n",
    "                \n",
    "        \n",
    "        tmp.append(merged)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(tmp)):\n",
    "    merged = tmp[k]\n",
    "    for i in range(len(merged)):\n",
    "        with open(str(k)+\"_\"+str(i)+merged[i][1]+\".csv\", \"w\") as f:\n",
    "            writer = c.writer(f)\n",
    "            for j in range(len( merged[i][0])):\n",
    "                if merged[i][1] == \"road\":\n",
    "                    appendix = [255,0,0]\n",
    "                elif merged[i][1] == \"stop\":\n",
    "                    appendix = [0,255,0]\n",
    "                else:\n",
    "                    appendix = [0,0,255]\n",
    "                \n",
    "                position = b.getXYFromIJ(np.array(merged[i][0][j]))\n",
    "                \n",
    "                    \n",
    "                writer.writerow(position.tolist()+height+appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(tmp)):\n",
    "    merged = tmp[k]\n",
    "    for i in range(len(merged)):\n",
    "        with open(str(k)+\"_\"+str(i)+merged[i][1]+\".csv\", \"w\") as f:\n",
    "            writer = c.writer(f)\n",
    "            for j in range(len( merged[i][0])):\n",
    "                if merged[i][1] == \"road\":\n",
    "                    appendix = [255,0,0]\n",
    "                elif merged[i][1] == \"stop\":\n",
    "                    appendix = [0,255,0]\n",
    "                else:\n",
    "                    appendix = [0,0,255]\n",
    "                \n",
    "                position = b.getXYFromIJ(np.array(merged[i][0][j]))\n",
    "                \n",
    "                    \n",
    "                writer.writerow(position.tolist()+height+appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = gray_2_rgb(b.pixels)\n",
    "Image.fromarray(rgb).save(\"QQ.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.909761034352705\n",
      "49.798727843165715\n",
      "45.10671108178235\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "cc = 0\n",
    "for roadmark in q:\n",
    "    cc+= 1\n",
    "    if 20<roadmark.length <60:\n",
    "        \n",
    "        if 1.5<roadmark.width <10:\n",
    "            r = roadmark.points.tolist()\n",
    "            for point in r:\n",
    "                point += [0,255,255,0]\n",
    "            tmp += r\n",
    "#     if 35<roadmark.length <60:\n",
    "#         if 5<roadmark.width <10:\n",
    "#             r = roadmark.points.tolist()\n",
    "#             for point in r:\n",
    "#                 point += [0,110,255,135]\n",
    "#             tmp += r\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv as c\n",
    "with open(\"tr.csv\",\"w\")as f:\n",
    "    wr = c.writer(f)\n",
    "    for i in range(len(tmp)):\n",
    "        wr.writerow(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98427515 -0.17664212]\n",
      " [ 0.17664212  0.98427515]]\n",
      "[[ 0.98302295 -0.18348265]\n",
      " [ 0.18348265  0.98302295]]\n",
      "[[ 0.98112743 -0.19336229]\n",
      " [ 0.19336229  0.98112743]]\n"
     ]
    }
   ],
   "source": [
    "#straight\n",
    "for i in range(3):\n",
    "    print(q[i].vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15497479 -0.98791842]\n",
      " [-0.98791842 -0.15497479]]\n",
      "[[ 0.16243637 -0.98671902]\n",
      " [-0.98671902 -0.16243637]]\n",
      "[[ 0.14934165 -0.98878566]\n",
      " [-0.98878566 -0.14934165]]\n"
     ]
    }
   ],
   "source": [
    "#cross\n",
    "for i in range(3):\n",
    "    print(q[i].vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.14563107 21.49838188]\n",
      "[24.04040404 24.51515152]\n",
      "[42.36567164 27.58955224]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(q[i].center)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
